{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>4732.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hi 1200d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4376.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chevy c20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4615.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ford f250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dodge d200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>oldsmobile omega</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mpg  cylinders  displacement  horsepower  weight  acceleration  model_year  \\\n",
       "0 -1.0        8.0         304.0       193.0  4732.0          18.5        70.0   \n",
       "1 -1.0        8.0         307.0       200.0  4376.0          15.0        70.0   \n",
       "2 -1.0        8.0         360.0       215.0  4615.0          14.0        70.0   \n",
       "3 -1.0        8.0         318.0       210.0  4382.0          13.5        70.0   \n",
       "4 -1.0        8.0         350.0       180.0  3664.0          11.0        73.0   \n",
       "\n",
       "   origin          car_name  \n",
       "0     1.0          hi 1200d  \n",
       "1     1.0         chevy c20  \n",
       "2     1.0         ford f250  \n",
       "3     1.0        dodge d200  \n",
       "4     1.0  oldsmobile omega  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "car_data = pd.read_csv(\"auto-mpg.tsv\", sep=\"\\t\")\n",
    "car_data = car_data.dropna()\n",
    "car_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. For each feature from the following:  [cylinders, displacement, horsepower, weight, acceleration, model_year, origin] indicate how you can represent it so as to make classification easier and get good generalization on unseen data, by choosing one of: 'drop' - leave the feature out, 'raw' - use values as they are, 'standard' - standardize values by subtracting out the average value and dividing by standard deviation, 'one-hot' - use a one-hot encoding.  There could be multiple answers that make sense for each feature; please mention the tradeoffs between each answer. Write down your choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cylinders\n",
    "- **One-hot**: âœ… as cylinders are discrete, allowing model to find non-linear connections between cylinder count and fuel efficiency.\n",
    "- **Raw**: ðŸ¤” if the link between cylinders and efficiency is almost linear\n",
    "- **Standard**: âŒ due to its discrete nature.\n",
    "- **Drop**: âŒ related to efficiency\n",
    "2. Displacement\n",
    "- **Standard**: âœ… it's a continuous variable; standardization aids in linear relationship cases.\n",
    "- **Raw**: ðŸ¤” possible, but standardization often enhances model convergence and performance.\n",
    "- **Drop**: âŒ related to fuel efficiency\n",
    "- **One-hot**: âŒ doesn't apply\n",
    "3. Horsepower\n",
    "- **Standard**: âœ… standardizing horsepower helps if it's linearly related to efficiency.\n",
    "- **Raw**: ðŸ¤” standardization usually yields superior results.\n",
    "- **Drop**: âŒ related to fuel efficiency\n",
    "- **One-hot**: âŒ doesn't apply\n",
    "4. Weight\n",
    "- **Standard**: âœ… weight is continuous and probably linearly related to efficiency.\n",
    "- **Raw**: ðŸ¤” possible, but standardization often enhances model convergence and performance.\n",
    "- **Drop**: âŒ related to fuel efficiency\n",
    "- **One-hot**: âŒ doesn't apply\n",
    "5. Acceleration\n",
    "- **Standard**: âœ… with weight and horsepower; normalization benefits certain models.\n",
    "- **Raw**: ðŸ¤” possible, but standardization often enhances model convergence and performance.\n",
    "- **Drop**: âŒ related to fuel efficiency\n",
    "- **One-hot**: âŒ doesn't apply\n",
    "\n",
    "6.Model Year\n",
    "- **One-hot**:  âœ… as model years are discrete, allowing model to find non-linear connections between model year and fuel efficiency.\n",
    "- **Raw**:  ðŸ¤” possible, but one-hot encoding is likely superior.\n",
    "- **Drop**: âŒ new car tech makes it relevant.\n",
    "- **Standard**: âŒ doesn't apply\n",
    "7. Origin\n",
    "- **One-hot**: ðŸ¤” as model years are discrete, allowing model to find non-linear connections between origin and fuel efficiency.\n",
    "- **Raw**:  ðŸ¤” possible, but one-hot encoding is likely superior.\n",
    "- **Standard**:ðŸ¤” possible, but one-hot encoding is likely superior.\n",
    "- **Drop**:  ðŸ¤” only if very low correlation to efficiency\n",
    "\n",
    "\n",
    "Key:\n",
    "- âœ… Yes\n",
    "- ðŸ¤” Maybe\n",
    "- âŒ No\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hi 1200d', 'chevy c20', 'ford f250', 'dodge d200',\n",
       "       'oldsmobile omega', 'chevrolet impala', 'mercury marquis',\n",
       "       'oldsmobile delta 88 royale', 'oldsmobile vista cruiser',\n",
       "       'dodge monaco (sw)', 'ford country', 'mercury marquis brougham',\n",
       "       'buick electra 225 custom', 'ford mustang ii', 'ford f108',\n",
       "       'ford gran torino (sw)', 'chevrolet chevelle concours (sw)',\n",
       "       'dodge d100', 'plymouth volare premier v8', 'chevrolet malibu',\n",
       "       'chevy c10', 'buick century luxus (sw)', 'buick lesabre custom',\n",
       "       'buick century 350', 'ford ltd', 'plymouth custom suburb',\n",
       "       'amc ambassador brougham', 'chevrolet caprice classic',\n",
       "       'ford country squire (sw)', 'pontiac safari (sw)',\n",
       "       'chrysler newport royal', 'chrysler new yorker brougham',\n",
       "       'ford gran torino', 'amc matador', 'amc matador (sw)',\n",
       "       'plymouth satellite custom (sw)', 'plymouth fury iii',\n",
       "       'plymouth fury gran sedan', 'dodge coronet custom (sw)',\n",
       "       \"plymouth 'cuda 340\", 'ford galaxie 500', 'pontiac catalina',\n",
       "       'pontiac catalina brougham', 'buick estate wagon (sw)',\n",
       "       'chevrolet nova', 'ford maverick', 'mercury monarch',\n",
       "       'mercury cougar brougham', 'dodge dart custom',\n",
       "       'dodge coronet custom', 'chevrolet monte carlo s',\n",
       "       'chevrolet bel air', 'buick skylark 320', 'dodge challenger se',\n",
       "       'amc ambassador dpl', 'chevrolet monte carlo',\n",
       "       'dodge monaco brougham', 'chevrolet monte carlo landau',\n",
       "       'chrysler cordoba', 'plymouth satellite custom',\n",
       "       'chevrolet nova custom', 'chevrolet chevelle malibu classic',\n",
       "       'chevroelt chevelle malibu', 'amc rebel sst',\n",
       "       'dodge coronet brougham', 'plymouth grand fury',\n",
       "       'ford thunderbird', 'pontiac grand prix lj', 'pontiac grand prix',\n",
       "       'peugeot 604sl', 'mercedes-benz 280s', 'cadillac seville',\n",
       "       'mercury grand marquis', 'volvo 264gl', 'buick century',\n",
       "       'chevrolet chevelle malibu', 'oldsmobile cutlass supreme',\n",
       "       'ford torino', 'amc ambassador sst', 'chevrolet concours',\n",
       "       'amc pacer d/l', 'dodge magnum xe', 'chrysler lebaron salon',\n",
       "       'ford ltd landau', 'buick regal sport coupe (turbo)', 'maxda rx3',\n",
       "       'volvo 145e (sw)', 'ford pinto', 'amc hornet', 'plymouth valiant',\n",
       "       'plymouth satellite sebring', 'plymouth fury', 'amc gremlin',\n",
       "       'ford granada ghia', 'ford mustang', 'amc hornet sportabout (sw)',\n",
       "       'plymouth satellite', 'amc concord d/l', 'ford futura',\n",
       "       'dodge st. regis', 'pontiac ventura sj', 'ford granada',\n",
       "       'chrysler lebaron town @ country (sw)', 'dodge aspen',\n",
       "       'mazda rx2 coupe', 'peugeot 504', 'volvo 144ea', 'toyota mark ii',\n",
       "       'plymouth volare custom', 'plymouth valiant custom', 'amc pacer',\n",
       "       'pontiac firebird', 'ford torino 500', 'pontiac phoenix lj',\n",
       "       'chevrolet malibu classic (sw)', 'amc concord', 'dodge diplomat',\n",
       "       'mercury zephyr 6', 'oldsmobile cutlass salon brougham',\n",
       "       'audi 100ls', 'volvo 245', 'chevrolet vega', 'toyota carina',\n",
       "       'plymouth duster', 'dodge aspen se', 'chevrolet monza 2+2',\n",
       "       'ford fairmont (auto)', 'ford granada gl', 'amc concord dl 6',\n",
       "       'mercury monarch ghia', 'audi 5000', 'plymouth volare',\n",
       "       'buick skylark', 'dodge aspen 6', 'buick century special',\n",
       "       'mercury zephyr', 'peugeot 504 (sw)', 'ford pinto runabout',\n",
       "       'mercury capri v6', 'buick skyhawk', 'toyota celica gt liftback',\n",
       "       'mazda rx-4', 'bmw 320i', 'pontiac lemans v6', 'saab 99gle',\n",
       "       'datsun 610', 'volkswagen 411 (sw)', 'volvo 244dl',\n",
       "       'ford pinto (sw)', 'chevrolet vega (sw)', 'datsun 810',\n",
       "       'ford granada l', 'ford fairmont 4', 'toyota corona mark ii (sw)',\n",
       "       'mercury capri 2000', 'pontiac astro', 'volkswagen type 3',\n",
       "       'cadillac eldorado', 'plymouth sapporo', 'chevrolet citation',\n",
       "       'mazda rx-7 gs', 'oldsmobile starfire sx', 'datsun 200-sx',\n",
       "       'audi 100 ls', 'toyota corona hardtop', 'toyota corona mark ii',\n",
       "       'opel manta', 'datsun 710', 'honda civic', 'saab 99le',\n",
       "       'toyota corona', 'ford fairmont futura', 'fiat 128',\n",
       "       'datsun 810 maxima', 'pontiac sunbird coupe', 'chevrolet woody',\n",
       "       'saab 99e', 'opel 1900', 'capri ii', 'volkswagen dasher',\n",
       "       'dodge colt hardtop', 'buick century limited',\n",
       "       'ford fairmont (man)', 'mercedes benz 300d', 'toyota cressida',\n",
       "       'plymouth arrow gs', 'ford mustang ii 2+2',\n",
       "       'dodge aries wagon (sw)', 'subaru', 'fiat 124 tc', 'bmw 2002',\n",
       "       'chrysler lebaron medallion', 'plymouth cricket',\n",
       "       'renault 12 (sw)', 'volkswagen 1131 deluxe sedan',\n",
       "       'volkswagen super beetle', 'toyota corolla liftback', 'dodge colt',\n",
       "       'fiat 124 sport coupe', 'ford fairmont', 'oldsmobile cutlass ls',\n",
       "       'oldsmobile omega brougham', 'renault 12tl',\n",
       "       'chevrolet cavalier wagon', 'ford mustang gl', 'pontiac phoenix',\n",
       "       'chevrolet camaro', 'volkswagen model 111',\n",
       "       'toyota corolla 1600 (sw)', 'datsun pl510', 'datsun 510',\n",
       "       'plymouth reliant', 'amc spirit dl', 'fiat 131',\n",
       "       'chevrolet cavalier', 'ford ranger', 'chevrolet vega 2300',\n",
       "       'toyota corolla', 'datsun 510 (sw)', 'dodge colt (sw)',\n",
       "       'peugeot 505s turbo diesel', 'buick skylark limited',\n",
       "       'dodge aries se', 'chevrolet chevette', 'volkswagen rabbit',\n",
       "       'vw rabbit', 'volkswagen rabbit custom', 'audi fox',\n",
       "       'honda accord lx', 'toyota corona liftback', 'vokswagen rabbit',\n",
       "       'ford escort 2h', 'buick opel isuzu deluxe', 'mercedes-benz 240d',\n",
       "       'peugeot 304', 'fiat 124b', 'subaru dl', 'volvo diesel',\n",
       "       'dodge omni', 'pontiac j2000 se hatchback', 'chevy s-10',\n",
       "       'toyota corolla 1200', 'datsun b210', 'fiat x1.9',\n",
       "       'mazda glc custom', 'mazda 626', 'volkswagen scirocco',\n",
       "       'honda accord cvcc', 'datsun 210', 'vw rabbit custom',\n",
       "       'dodge rampage', 'toyota celica gt', 'datsun b-210',\n",
       "       'honda civic (auto)', 'honda accord', 'datsun 280-zx',\n",
       "       'mazda glc deluxe', 'datsun 200sx', 'volkswagen jetta',\n",
       "       'honda civic cvcc', 'datsun f-10 hatchback', 'dodge colt m/m',\n",
       "       'honda prelude', 'chevrolet cavalier 2-door', 'maxda glc deluxe',\n",
       "       'mazda glc 4', 'plymouth horizon', 'audi 4000', 'ford escort 4w',\n",
       "       'plymouth horizon tc3', 'plymouth horizon 4', 'triumph tr7 coupe',\n",
       "       'datsun 1200', 'honda civic 1300', 'dodge colt hatchback custom',\n",
       "       'volkswagen rabbit l', 'nissan stanza xe', 'dodge charger 2.2',\n",
       "       'renault 5 gtl', 'mercury lynx l', 'ford fiesta',\n",
       "       'audi 5000s (diesel)', 'datsun 510 hatchback', 'datsun 210 mpg',\n",
       "       'mazda glc custom l', 'datsun 310', 'fiat strada custom',\n",
       "       'toyota tercel', 'plymouth horizon miser', 'datsun 310 gx',\n",
       "       'oldsmobile cutlass ciera (diesel)', 'toyota corolla tercel',\n",
       "       'plymouth champ', 'toyota starlet', 'datsun b210 gx',\n",
       "       'volkswagen rabbit custom diesel', 'vw dasher (diesel)',\n",
       "       'vw pickup', 'vw rabbit c (diesel)', 'honda civic 1500 gl',\n",
       "       'mazda glc'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_features = ['cylinders', 'origin', 'model_year']\n",
    "continuous_features = ['displacement', 'horsepower', 'weight', 'acceleration']\n",
    "\n",
    "# Preprocess numerical features (standardization)\n",
    "for feature in continuous_features:\n",
    "    mean_value = car_data[feature].mean()\n",
    "    std_dev = car_data[feature].std()\n",
    "    car_data[feature] = (car_data[feature] - mean_value) / std_dev\n",
    "\n",
    "# Preprocess categorical features (one-hot encoding)\n",
    "for feature in discrete_features:\n",
    "    unique_vals = car_data[feature].unique()\n",
    "    for val in unique_vals:\n",
    "        feat_name = f\"{feature}_{val}\"\n",
    "        car_data[feat_name] = (car_data[feature] == val).astype(int)\n",
    "car_data[\"car_name\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. How can car name, a textual feature, be transformed into a feature which can be used by the logistic regression algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Name Transformation\n",
    "For logistic regression and decision tree algorithms to effectively utilize these features, it needs conversion into numerical values. \n",
    "\n",
    "#### Logistic Regression\n",
    "- **Label Encoding**: Assigns each unique car name an integer but assumes an ordinal relationship, which may not fit nominal data like car names.\n",
    "- **Text Embeddings**: Utilizes complex text processing (e.g., word embeddings) if car names contain structured elements like brand and model. Could be excessive for simple categorical text.\n",
    "- **One-hot Encoding**: Feasible if the count of unique car names is manageable. However, numerous unique names may cause high-dimensional feature sets (the curse of dimensionality).\n",
    "- **Feature Hashing (Hashing Trick)**: Converts categories to a fixed-size of numerical values, suitable for handling a large number of categories. More space-efficient but can lead to collisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of hashing\n",
    "car_data['car_name_hashed'] = car_data['car_name'].apply(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3.  How can car name, a textual feature, be transformed into a feature which can be used by the decision tree algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual to Numerical Conversion\n",
    "To proceed as described in the previous section, we'll convert textual data into numerical format.\n",
    "\n",
    "#### Decision Tree Algorithm\n",
    "- **Label Encoding**: Works for decision trees and their ensembles (e.g., random forests) as they handle categorical data well. The ordinal nature of label encoding isn't a major concern for tree-based methods, unlike linear models.\n",
    "- **One-hot Encoding**: Applicable with a moderate count of unique car names. might complicate the tree's structure.\n",
    "- **Binary Encoding**: An in between label and one-hot encoding, creating binary columns with fewer dimensions. Effective for moderately high cardinality categorical variables.\n",
    "- **Feature Hashing**: useful for handling numerous categories to reduce dimensionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding Example\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "car_data['car_name_encoded'] = label_encoder.fit_transform(car_data['car_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4. For this dataset is car name informative, useful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Association**: \"Car name\" typically encompasses make and model details, indirectly linked to fuel efficiency due to design and engine variations among models.\n",
    "- **Dataset Diversity**: The feature's utility relies heavily on dataset specifics. A limited dataset regarding car names might restrict its predictive value.\n",
    "- **Granularity Impact**: Specific features like \"car name\" can induce overfitting, especially in smaller datasets. Models might learn overly specific patterns, reducing generalization ability.\n",
    "- **Feature Engineering Potential**: Extracting manufacturer information or other details from \"car name\" could enhance its utility when combined with other features, offering insights into consumption patterns related to manufacturers.\n",
    "\n",
    "So, based on this and low correlation in the data therefore implies that it isn't informative to our prediction and we can drop it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5. Based on choices you made in (1) above make a feature matrix that you can use as an input to sklearn.tree.DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>cylinders_8.0</th>\n",
       "      <th>cylinders_6.0</th>\n",
       "      <th>cylinders_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>model_year_76.0</th>\n",
       "      <th>model_year_74.0</th>\n",
       "      <th>model_year_77.0</th>\n",
       "      <th>model_year_79.0</th>\n",
       "      <th>model_year_78.0</th>\n",
       "      <th>model_year_81.0</th>\n",
       "      <th>model_year_80.0</th>\n",
       "      <th>model_year_82.0</th>\n",
       "      <th>car_name_hashed</th>\n",
       "      <th>car_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.956315</td>\n",
       "      <td>0.271330</td>\n",
       "      <td>-0.957831</td>\n",
       "      <td>2.377309</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6664437763177975671</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.278900</td>\n",
       "      <td>-1.075659</td>\n",
       "      <td>0.817534</td>\n",
       "      <td>-1.464852</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6247184583113605697</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.328074</td>\n",
       "      <td>0.480861</td>\n",
       "      <td>-1.194468</td>\n",
       "      <td>-0.014980</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3684250617797406736</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.278900</td>\n",
       "      <td>-1.075659</td>\n",
       "      <td>0.536160</td>\n",
       "      <td>-1.283618</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6853782529698776536</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.126800</td>\n",
       "      <td>-1.030759</td>\n",
       "      <td>0.842258</td>\n",
       "      <td>-1.464852</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8205199783614854769</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.821171</td>\n",
       "      <td>1.139389</td>\n",
       "      <td>-0.262048</td>\n",
       "      <td>0.093761</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1083050989054830603</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.913754</td>\n",
       "      <td>1.019657</td>\n",
       "      <td>-0.473962</td>\n",
       "      <td>0.238748</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4907723336078447246</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.540116</td>\n",
       "      <td>1.169322</td>\n",
       "      <td>0.474941</td>\n",
       "      <td>1.144918</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6437112557822341566</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.768266</td>\n",
       "      <td>1.229188</td>\n",
       "      <td>-0.420983</td>\n",
       "      <td>-0.413694</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4661506389800659704</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.540116</td>\n",
       "      <td>-1.210358</td>\n",
       "      <td>0.168843</td>\n",
       "      <td>0.347488</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7825899653007573159</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement  horsepower    weight  acceleration  model_year  \\\n",
       "0          4.0      1.956315    0.271330 -0.957831      2.377309        76.0   \n",
       "1          8.0     -0.278900   -1.075659  0.817534     -1.464852        73.0   \n",
       "2          4.0      1.328074    0.480861 -1.194468     -0.014980        74.0   \n",
       "3          8.0     -0.278900   -1.075659  0.536160     -1.283618        70.0   \n",
       "4          8.0     -0.126800   -1.030759  0.842258     -1.464852        70.0   \n",
       "..         ...           ...         ...       ...           ...         ...   \n",
       "387        4.0     -0.821171    1.139389 -0.262048      0.093761        77.0   \n",
       "388        4.0     -0.913754    1.019657 -0.473962      0.238748        82.0   \n",
       "389        6.0     -0.540116    1.169322  0.474941      1.144918        80.0   \n",
       "390        4.0     -0.768266    1.229188 -0.420983     -0.413694        81.0   \n",
       "391        6.0     -0.540116   -1.210358  0.168843      0.347488        73.0   \n",
       "\n",
       "     origin  cylinders_8.0  cylinders_6.0  cylinders_3.0  ...  \\\n",
       "0       1.0              0              0              0  ...   \n",
       "1       1.0              1              0              0  ...   \n",
       "2       2.0              0              0              0  ...   \n",
       "3       1.0              1              0              0  ...   \n",
       "4       1.0              1              0              0  ...   \n",
       "..      ...            ...            ...            ...  ...   \n",
       "387     1.0              0              0              0  ...   \n",
       "388     1.0              0              0              0  ...   \n",
       "389     1.0              0              1              0  ...   \n",
       "390     1.0              0              0              0  ...   \n",
       "391     1.0              0              1              0  ...   \n",
       "\n",
       "     model_year_76.0  model_year_74.0  model_year_77.0  model_year_79.0  \\\n",
       "0                  1                0                0                0   \n",
       "1                  0                0                0                0   \n",
       "2                  0                1                0                0   \n",
       "3                  0                0                0                0   \n",
       "4                  0                0                0                0   \n",
       "..               ...              ...              ...              ...   \n",
       "387                0                0                1                0   \n",
       "388                0                0                0                0   \n",
       "389                0                0                0                0   \n",
       "390                0                0                0                0   \n",
       "391                0                0                0                0   \n",
       "\n",
       "     model_year_78.0  model_year_81.0  model_year_80.0  model_year_82.0  \\\n",
       "0                  0                0                0                0   \n",
       "1                  0                0                0                0   \n",
       "2                  0                0                0                0   \n",
       "3                  0                0                0                0   \n",
       "4                  0                0                0                0   \n",
       "..               ...              ...              ...              ...   \n",
       "387                0                0                0                0   \n",
       "388                0                0                0                1   \n",
       "389                0                0                1                0   \n",
       "390                0                1                0                0   \n",
       "391                0                0                0                0   \n",
       "\n",
       "         car_name_hashed  car_name_encoded  \n",
       "0    6664437763177975671                65  \n",
       "1    6247184583113605697                 9  \n",
       "2    3684250617797406736               280  \n",
       "3    6853782529698776536                13  \n",
       "4   -8205199783614854769                35  \n",
       "..                   ...               ...  \n",
       "387 -1083050989054830603               153  \n",
       "388 -4907723336078447246               244  \n",
       "389 -6437112557822341566                97  \n",
       "390 -4661506389800659704                96  \n",
       "391 -7825899653007573159               233  \n",
       "\n",
       "[392 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_data = car_data.drop(['mpg','car_name'], axis=1)[:]\n",
    "y_data = car_data['mpg'][:]\n",
    "\n",
    "np.random.seed(17)\n",
    "shuffle = np.random.permutation(X_data.index)\n",
    "\n",
    "X_data = X_data.loc[shuffle].reset_index(drop=True)\n",
    "y_data = y_data.loc[shuffle].reset_index(drop=True)\n",
    "\n",
    "X_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">6. PROGRAM (not use sklearn or other libraries) 10 fold cross validation method to train and evaluate a decision tree classifier on this data. Note you can use sklearn.tree.DecisionTreeClassifier to build the tree for each fold. Report final results for all three criterion used in sklearn.tree.DecisionTreeClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy 0.8846153846153847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "num_folds = 10\n",
    "fold_size = len(X_data) // num_folds\n",
    "\n",
    "X_folds = [X_data[i * fold_size: (i + 1) * fold_size] for i in range(num_folds)]\n",
    "y_folds = [y_data[i * fold_size: (i + 1) * fold_size] for i in range(num_folds)]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(num_folds):\n",
    "    X_train = np.concatenate([fold for j, fold in enumerate(X_folds) if j != i])\n",
    "    y_train = np.concatenate([fold for j, fold in enumerate(y_folds) if j != i])\n",
    "    X_val, y_val = X_folds[i], y_folds[i]\n",
    "\n",
    "    dct = DecisionTreeClassifier()\n",
    "    dct.fit(X_train, y_train)\n",
    "    y_pred = dct.predict(X_val)\n",
    "    \n",
    "    accuracy = (np.sum(y_val == y_pred) / len(y_val))\n",
    "    results.append(accuracy)\n",
    "\n",
    "mean = np.mean(results)\n",
    "print(\"Mean Accuracy\", mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/parzuko/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "extra_params = {\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 8,\n",
    "    'max_features': 'sqrt',  \n",
    "    'criterion': 'gini' }\n",
    "\n",
    "num_folds = 10\n",
    "fold_size = len(X_data) // num_folds\n",
    "\n",
    "X_folds = [X_data[i * fold_size: (i + 1) * fold_size] for i in range(num_folds)]\n",
    "y_folds = [y_data[i * fold_size: (i + 1) * fold_size] for i in range(num_folds)]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(num_folds):\n",
    "    X_train = np.concatenate([fold for j, fold in enumerate(X_folds) if j != i])\n",
    "    y_train = np.concatenate([fold for j, fold in enumerate(y_folds) if j != i])\n",
    "    X_val, y_val = X_folds[i], y_folds[i]\n",
    "\n",
    "    dct = DecisionTreeClassifier(**extra_params)\n",
    "    dct.fit(X_train, y_train)\n",
    "    y_pred = dct.predict(X_val)\n",
    "    \n",
    "    accuracy = (np.sum(y_val == y_pred) / len(y_val))\n",
    "    results.append(accuracy)\n",
    "\n",
    "mean = np.mean(results)\n",
    "print(\"Mean Accuracy\", mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
