{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pickle\n",
    "\n",
    "def NB_XGivenY(XTrain, yTrain, a=0.001, b=0.9):\n",
    "    \"\"\"\n",
    "    Compute the probability of P(X|Y).\n",
    "\n",
    "    :param\n",
    "        XTrain: numpy array of size [num_samples, feat_dim]\n",
    "          where num_samples is the number of samples\n",
    "          and feat_dim is the dimension of features\n",
    "        yTrain: numpy array of size [num_samples, 1]\n",
    "        a: default to 0.001\n",
    "        b: default to 0.9\n",
    "\n",
    "    :return: \n",
    "        D: numpy array of size [2, vocab_size] where\n",
    "          vocab_size is the size of vocabulary\n",
    "    \"\"\"\n",
    "    samples, vocab = XTrain.shape\n",
    "    D = np.zeros((2, vocab))\n",
    "\n",
    "    for i in range(vocab):\n",
    "        D[0, i] = (np.sum(XTrain[yTrain[:, 0] == 1, i]) + a) / (np.sum(yTrain == 1) + a + b)\n",
    "        D[1, i] = (np.sum(XTrain[yTrain[:, 0] == 2, i]) + a) / (np.sum(yTrain == 2) + a + b)\n",
    "    return D\n",
    "\n",
    "\n",
    "def NB_YPrior(yTrain):\n",
    "    \"\"\"\n",
    "    Compute the probability of P(Y).\n",
    "\n",
    "    :param\n",
    "        yTrain: numpy array of size [num_samples, 1]\n",
    "\n",
    "    :return: \n",
    "        p: a scalar for the probability of P(Y = 1)\n",
    "    \"\"\"\n",
    "    p = np.sum(yTrain == 1) / len(yTrain)\n",
    "    return p\n",
    "\n",
    "\n",
    "def NB_Classify(D, p, X):\n",
    "    \"\"\"\n",
    "    Predict the labels of X.\n",
    "\n",
    "    :param\n",
    "        D: the probability P(X|Y)\n",
    "        p: the probability P(Y)\n",
    "        X: numpy array of size [num_samples, feat_dim]\n",
    "          where num_samples is the number of samples\n",
    "          and feat_dim is the dimension of features\n",
    "\n",
    "    :return: \n",
    "        y: numpy array of size [num_samples, 1] where\n",
    "            num_samples is the number of samples\n",
    "    \"\"\"\n",
    "    num_samples, _ = X.shape\n",
    "    y = np.zeros((num_samples, 1))\n",
    "\n",
    "    log_dataset = np.log(D)\n",
    "    log_dataset_inv = np.log(1 - D)\n",
    "    log_prior = np.log(p)\n",
    "    log_prior_inv = np.log(1 - p)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        log_likelihood_1 = np.sum(X[i, :] * log_dataset[0, :]) + np.sum((1 - X[i, :]) * log_dataset_inv[0, :]) + log_prior\n",
    "        log_likelihood_2 = np.sum(X[i, :] * log_dataset[1, :]) + np.sum((1 - X[i, :]) * log_dataset_inv[1, :]) + log_prior_inv\n",
    "        y[i, 0] = 1 if log_likelihood_1 > log_likelihood_2 else 2\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def NB_ClassificationAccuracy(yHat, yTruth):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of predictions.\n",
    "\n",
    "    :param\n",
    "        yHat: numpy array of size [num_samples, 1]\n",
    "        yTruth: numpy array of size [num_samples, 1]\n",
    "    \n",
    "    :return:\n",
    "        acc: a scalar for the accuracy\n",
    "    \"\"\"\n",
    "    acc = np.sum(yHat == yTruth) / len(yTruth)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 97.39%\n",
      "Confusion Matrix:\n",
      " [[103   0]\n",
      " [  4  46]]\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "The Economist       0.96      1.00      0.98       103\n",
      "    The Onion       1.00      0.92      0.96        50\n",
      "\n",
      "     accuracy                           0.97       153\n",
      "    macro avg       0.98      0.96      0.97       153\n",
      " weighted avg       0.97      0.97      0.97       153\n",
      "\n",
      "Top 10 words that are most indicative of The Economist:\n",
      "1. ['4enlarg']\n",
      "2. ['5enlarg']\n",
      "3. ['percent']\n",
      "4. ['realiz']\n",
      "5. ['center']\n",
      "6. ['myself']\n",
      "7. ['approxim']\n",
      "8. ['honor']\n",
      "9. ['fuck']\n",
      "10. ['favor']\n",
      "Top 10 words that are most indicative of The Onion:\n",
      "1. ['parliament']\n",
      "2. ['organis']\n",
      "3. ['favour']\n",
      "4. ['labour']\n",
      "5. ['reckon']\n",
      "6. ['centr']\n",
      "7. ['neighbour']\n",
      "8. ['conserv']\n",
      "9. ['parliamentari']\n",
      "10. ['boost']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Loading data from file\n",
    "with open('hwdata.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "word_vocabulary = data['Vocabulary']\n",
    "training_features = data['XTrain']\n",
    "training_labels = data['yTrain']\n",
    "test_features = data['XTest']\n",
    "test_labels = data['yTest']\n",
    "\n",
    "# Training Naive Bayes\n",
    "likelihood_given_y = NB_XGivenY(training_features, training_labels)\n",
    "prior_prob_y = NB_YPrior(training_labels)\n",
    "\n",
    "# Classifying\n",
    "predicted_labels = NB_Classify(likelihood_given_y, prior_prob_y, test_features)\n",
    "\n",
    "accuracy = NB_ClassificationAccuracy(predicted_labels, test_labels)\n",
    "print(f\"Test Accuracy : {accuracy * 100:.2f}%\")\n",
    "\n",
    "confusion_mat = confusion_matrix(test_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "\n",
    "# Classification Report \n",
    "class_report = classification_report(test_labels, predicted_labels, target_names=['The Economist', 'The Onion'])\n",
    "print(\"Report:\", class_report)\n",
    "\n",
    "\n",
    "log_prob_ratio = np.log(likelihood_given_y[0, :]) - np.log(likelihood_given_y[1, :])\n",
    "\n",
    "sorted_indices = np.argsort(log_prob_ratio)\n",
    "# Printing the top 10 words for each class\n",
    "def print_top_words(class_name, indices, vocabulary):\n",
    "    print(f\"Top 10 words that are most indicative of {class_name}:\")\n",
    "    for i in range(10):\n",
    "        print(f\"{i + 1}. {vocabulary[indices[i]]}\")\n",
    "\n",
    "print_top_words('The Economist', sorted_indices, word_vocabulary)\n",
    "print_top_words('The Onion', sorted_indices[::-1], word_vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
