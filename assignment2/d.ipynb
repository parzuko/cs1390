{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":580,"status":"ok","timestamp":1700981261028,"user":{"displayName":"Diya Roongta","userId":"11843916732539153564"},"user_tz":-330},"id":"tq7V-oJRIvxl","outputId":"34bc1ad3-5e1e-4fb6-9f81-56e9c5b6f249"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mpg</th>\n","      <th>cylinders</th>\n","      <th>displacement</th>\n","      <th>horsepower</th>\n","      <th>weight</th>\n","      <th>acceleration</th>\n","      <th>model_year</th>\n","      <th>origin</th>\n","      <th>car_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.0</td>\n","      <td>8.0</td>\n","      <td>304.0</td>\n","      <td>193.0</td>\n","      <td>4732.0</td>\n","      <td>18.5</td>\n","      <td>70.0</td>\n","      <td>1.0</td>\n","      <td>hi 1200d</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1.0</td>\n","      <td>8.0</td>\n","      <td>307.0</td>\n","      <td>200.0</td>\n","      <td>4376.0</td>\n","      <td>15.0</td>\n","      <td>70.0</td>\n","      <td>1.0</td>\n","      <td>chevy c20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.0</td>\n","      <td>8.0</td>\n","      <td>360.0</td>\n","      <td>215.0</td>\n","      <td>4615.0</td>\n","      <td>14.0</td>\n","      <td>70.0</td>\n","      <td>1.0</td>\n","      <td>ford f250</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1.0</td>\n","      <td>8.0</td>\n","      <td>318.0</td>\n","      <td>210.0</td>\n","      <td>4382.0</td>\n","      <td>13.5</td>\n","      <td>70.0</td>\n","      <td>1.0</td>\n","      <td>dodge d200</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.0</td>\n","      <td>8.0</td>\n","      <td>350.0</td>\n","      <td>180.0</td>\n","      <td>3664.0</td>\n","      <td>11.0</td>\n","      <td>73.0</td>\n","      <td>1.0</td>\n","      <td>oldsmobile omega</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>900.0</td>\n","      <td>480.0</td>\n","      <td>2335.0</td>\n","      <td>23.7</td>\n","      <td>80.0</td>\n","      <td>2.0</td>\n","      <td>vw dasher (diesel)</td>\n","    </tr>\n","    <tr>\n","      <th>389</th>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>970.0</td>\n","      <td>520.0</td>\n","      <td>2130.0</td>\n","      <td>24.6</td>\n","      <td>82.0</td>\n","      <td>2.0</td>\n","      <td>vw pickup</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>900.0</td>\n","      <td>480.0</td>\n","      <td>2085.0</td>\n","      <td>21.7</td>\n","      <td>80.0</td>\n","      <td>2.0</td>\n","      <td>vw rabbit c (diesel)</td>\n","    </tr>\n","    <tr>\n","      <th>391</th>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>910.0</td>\n","      <td>670.0</td>\n","      <td>1850.0</td>\n","      <td>13.8</td>\n","      <td>80.0</td>\n","      <td>3.0</td>\n","      <td>honda civic 1500 gl</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>860.0</td>\n","      <td>650.0</td>\n","      <td>2110.0</td>\n","      <td>17.9</td>\n","      <td>80.0</td>\n","      <td>3.0</td>\n","      <td>mazda glc</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>393 rows Ã— 9 columns</p>\n","</div>"],"text/plain":["     mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n","0   -1.0        8.0         304.0       193.0  4732.0          18.5   \n","1   -1.0        8.0         307.0       200.0  4376.0          15.0   \n","2   -1.0        8.0         360.0       215.0  4615.0          14.0   \n","3   -1.0        8.0         318.0       210.0  4382.0          13.5   \n","4   -1.0        8.0         350.0       180.0  3664.0          11.0   \n","..   ...        ...           ...         ...     ...           ...   \n","388  1.0        4.0         900.0       480.0  2335.0          23.7   \n","389  1.0        4.0         970.0       520.0  2130.0          24.6   \n","390  1.0        4.0         900.0       480.0  2085.0          21.7   \n","391  1.0        4.0         910.0       670.0  1850.0          13.8   \n","392  1.0        4.0         860.0       650.0  2110.0          17.9   \n","\n","     model_year  origin              car_name  \n","0          70.0     1.0              hi 1200d  \n","1          70.0     1.0             chevy c20  \n","2          70.0     1.0             ford f250  \n","3          70.0     1.0            dodge d200  \n","4          73.0     1.0      oldsmobile omega  \n","..          ...     ...                   ...  \n","388        80.0     2.0    vw dasher (diesel)  \n","389        82.0     2.0             vw pickup  \n","390        80.0     2.0  vw rabbit c (diesel)  \n","391        80.0     3.0   honda civic 1500 gl  \n","392        80.0     3.0             mazda glc  \n","\n","[393 rows x 9 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","data = pd.read_csv(\"auto-mpg.tsv\", sep='\\t', header=0)\n","data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":664,"status":"ok","timestamp":1700981264003,"user":{"displayName":"Diya Roongta","userId":"11843916732539153564"},"user_tz":-330},"id":"RhtyaFUDiSRf","outputId":"b87aae6a-5220-4e38-c9c3-f3741cd0e797"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 393 entries, 0 to 392\n","Data columns (total 9 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   mpg           392 non-null    float64\n"," 1   cylinders     392 non-null    float64\n"," 2   displacement  392 non-null    float64\n"," 3   horsepower    392 non-null    float64\n"," 4   weight        392 non-null    float64\n"," 5   acceleration  392 non-null    float64\n"," 6   model_year    392 non-null    float64\n"," 7   origin        392 non-null    float64\n"," 8   car_name      392 non-null    object \n","dtypes: float64(8), object(1)\n","memory usage: 27.8+ KB\n"]}],"source":["data.info()"]},{"cell_type":"markdown","metadata":{"id":"oRmEpATrr11e"},"source":["# 1.\n","Cylinders:\n","\n","Representation: 'standard'\n","Trade-offs: Standardizing helps when the range of values is significant. It ensures that all features are on a similar scale, preventing some features from dominating the learning process due to their larger values.\n","\n","Displacement:\n","\n","Representation: 'standard' (standardize values)\n","Trade-offs: Standardizing helps when the range of values is significant. It ensures that all features are on a similar scale, preventing some features from dominating the learning process due to their larger values.\n","Horsepower:\n","\n","Representation: 'standard' (standardize values)\n","Trade-offs: Similar to displacement, standardizing helps when the range of horsepower values is significant. It ensures that the model is not overly influenced by features with larger scales.\n","\n","Weight:\n","\n","Representation: 'standard' (standardize values)\n","Trade-offs: Standardizing is suitable as weight values can vary significantly. This ensures that the weight feature doesn't dominate the learning process.\n","\n","Acceleration:\n","\n","Representation: 'standard' (standardize values)\n","Trade-offs: Standardizing acceleration values can help maintain consistency with other standardized features, making the model more robust.\n","\n","Model Year:\n","\n","Representation: 'standard'\n","Trade-offs: Model year, although represented as a numerical value, is better treated as a categorical variable. One-hot encoding prevents the model from assuming ordinal relationships between different years. Moreover, the years not present in the dataset will then have to be treated as others.\n","\n","Origin:\n","\n","Representation: 'one-hot' encoding\n","Trade-offs: Similar to model year, origin is better treated as a categorical variable. One-hot encoding is appropriate to represent the different categories without implying any ordinal relationship."]},{"cell_type":"markdown","metadata":{"id":"36_oRd4NsPxD"},"source":["**Question A) Part 2**.\n","1. We will use the Bag-of-Words (BoW) Representation for car_names for logistic regression.\n","\n","This is because:\n","* BoW is a common technique in natural language processing where each car name is represented as an unordered set of words, not keeping track of word order but keeping track of word frequency.\n","* BoW representation is useful because we want to keep track of the presence/absence of car_names along with their frequencies.\n"]},{"cell_type":"markdown","metadata":{"id":"e6XqaEai1w-i"},"source":["**Question A) Part 3**.\n","\n","We can use Label encoding for the column 'car_names' to be used by the decision tree algorithm because decision trees operate on numerical values, and label encoding provides a way to represent categorical data with numerical labels.\n","\n","In label encoding, each category in the 'car_names' column is assigned a unique numerical label. This is beneficial for decision trees because it allows them to make splits based on these numerical labels. Decision trees partition the data by comparing feature values to thresholds, and numerical labels facilitate this process.\n","\n","Using one-hot encoding for 'car_names' could create a large number of binary columns, each representing a specific car name. While this is suitable for some algorithms, decision trees might struggle with high-dimensional, sparse data. Label encoding simplifies the representation by mapping each category to a numerical value, making it more manageable for decision trees to process."]},{"cell_type":"markdown","metadata":{"id":"5BhPGdHR2Ajp"},"source":["**Question A) Part 4**.\n","The \"car_name\" column in the dataset is not informative or useful for analysis or modeling purposes. It contains unique identifiers for each car, which does not contribute meaningful information to the label column of miles per gallon/mpg.\n","To prove this hypothesis, I have found the correlation between mpg with all of the other columns, and as can be seen, the correlation value is very minute with the encoded values of car names (0.05 or -0.007)\n"]},{"cell_type":"markdown","metadata":{"id":"ZEkZkH_mO7iz"},"source":["# QA) 5: Feature Matrix"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1700983297616,"user":{"displayName":"Diya Roongta","userId":"11843916732539153564"},"user_tz":-330},"id":"-vvqbSyHlLdB","outputId":"3ad8e88e-d4aa-4e2b-d5ba-501adfea0f59"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unexpected exception formatting exception. Falling back to standard exception\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/var/folders/7s/r6p1ylbx60502xvzn7f3f5p40000gn/T/ipykernel_23450/977226444.py\", line 7, in <module>\n","    X_data = df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin']]\n","NameError: name 'df' is not defined\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n","    frames.append(self.format_record(record))\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n","    frame_info.lines, Colors, self.has_colors, lvals\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 792, in lines\n","    return self._sd.lines\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 734, in lines\n","    pieces = self.included_pieces\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 677, in included_pieces\n","    scope_pieces = self.scope_pieces\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 614, in scope_pieces\n","    scope_start, scope_end = self.source.line_range(self.scope)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 178, in line_range\n","    return line_range(self.asttext(), node)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/executing/executing.py\", line 333, in asttext\n","    self._asttext = ASTText(self.text, tree=self.tree, filename=self.filename)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/asttokens/asttokens.py\", line 305, in __init__\n","    super(ASTText, self).__init__(source_text, filename)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/asttokens/asttokens.py\", line 47, in __init__\n","    source_text = six.ensure_text(source_text)\n","AttributeError: module 'six' has no attribute 'ensure_text'\n"]}],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","\n","# Assuming df is your dataframe\n","X_data = df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin']]\n","Y_data = df['mpg']\n","\n","# Creating transformers for numeric and categorical features\n","num_features = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin']\n","num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n","\n","cat_features = ['model_year']\n","cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder())])\n","\n","# Column transformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', num_transformer, num_features),\n","        ('cat', cat_transformer, cat_features),\n","    ])\n","\n","# Feature matrix\n","X_features_transformed = preprocessor.fit_transform(X_data)\n","print(X_features_transformed)\n"]},{"cell_type":"markdown","metadata":{"id":"YU1jg0VHPLSu"},"source":["# Part 6 and 7: Decision Tree Classifier\n","(With Bonus)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4j4B-d6sAtX3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unexpected exception formatting exception. Falling back to standard exception\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/var/folders/7s/r6p1ylbx60502xvzn7f3f5p40000gn/T/ipykernel_23450/1348774386.py\", line 1, in <module>\n","    X_features.shape\n","NameError: name 'X_features' is not defined\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n","    frames.append(self.format_record(record))\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n","    frame_info.lines, Colors, self.has_colors, lvals\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 792, in lines\n","    return self._sd.lines\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 734, in lines\n","    pieces = self.included_pieces\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 677, in included_pieces\n","    scope_pieces = self.scope_pieces\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 614, in scope_pieces\n","    scope_start, scope_end = self.source.line_range(self.scope)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 178, in line_range\n","    return line_range(self.asttext(), node)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/executing/executing.py\", line 333, in asttext\n","    self._asttext = ASTText(self.text, tree=self.tree, filename=self.filename)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/asttokens/asttokens.py\", line 305, in __init__\n","    super(ASTText, self).__init__(source_text, filename)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/asttokens/asttokens.py\", line 47, in __init__\n","    source_text = six.ensure_text(source_text)\n","AttributeError: module 'six' has no attribute 'ensure_text'\n"]}],"source":["X_features.shape\n","Y = Y.reshape(-1, 1)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":724,"status":"ok","timestamp":1700981132979,"user":{"displayName":"Diya Roongta","userId":"11843916732539153564"},"user_tz":-330},"id":"ixjSh0lhCbr8","outputId":"5e1f4184-1b5d-4ea8-b019-15b9fd58e143"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unexpected exception formatting exception. Falling back to standard exception\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/var/folders/7s/r6p1ylbx60502xvzn7f3f5p40000gn/T/ipykernel_23450/27163341.py\", line 45, in <module>\n","    custom_k_fold_split(X_features, Y)\n","NameError: name 'X_features' is not defined\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n","    frames.append(self.format_record(record))\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n","    frame_info.lines, Colors, self.has_colors, lvals\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py\", line 792, in lines\n","    return self._sd.lines\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 734, in lines\n","    pieces = self.included_pieces\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 677, in included_pieces\n","    scope_pieces = self.scope_pieces\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 614, in scope_pieces\n","    scope_start, scope_end = self.source.line_range(self.scope)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/stack_data/core.py\", line 178, in line_range\n","    return line_range(self.asttext(), node)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/executing/executing.py\", line 333, in asttext\n","    self._asttext = ASTText(self.text, tree=self.tree, filename=self.filename)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/asttokens/asttokens.py\", line 305, in __init__\n","    super(ASTText, self).__init__(source_text, filename)\n","  File \"/Users/parzuko/Library/Python/3.9/lib/python/site-packages/asttokens/asttokens.py\", line 47, in __init__\n","    source_text = six.ensure_text(source_text)\n","AttributeError: module 'six' has no attribute 'ensure_text'\n"]}],"source":["import numpy as np\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Set a random seed for reproducibility, can delete to see different\n","np.random.seed(42)\n","\n","accuracy_list, precision_list, recall_list = [], [], []\n","\n","num_samples = len(data)\n","num_folds = 10\n","split_criteria = ['gini', 'entropy', 'log_loss']\n","\n","def custom_k_fold_split(features, labels, folds=10):\n","    fold_size = len(labels) // folds\n","    indices = np.random.permutation(len(labels))\n","\n","    for criterion in split_criteria:\n","        for i in range(folds):\n","            start, end = i * fold_size, (i + 1) * fold_size\n","            val_indices = indices[start:end]\n","            train_indices = np.concatenate([indices[:start], indices[end:]])\n","\n","            features_val, labels_val = features[val_indices], labels[val_indices]\n","            features_train, labels_train = features[train_indices], labels[train_indices]\n","\n","            # Training\n","            tree_classifier = DecisionTreeClassifier(criterion=criterion)\n","            tree_classifier.fit(features_train, labels_train)\n","\n","            # Predicting on test dataset\n","            predictions = tree_classifier.predict(features_val)\n","\n","            # calculating accuracy values\n","            accuracy = sum(labels_val == predictions) / len(labels_val)\n","            precision = np.sum((labels_val == 1) & (predictions == 1)) / (\n","                    np.sum((labels_val == 1) & (predictions == 1)) + np.sum((labels_val == -1) & (predictions == 1)))\n","            recall = np.sum((labels_val == 1) & (predictions == 1)) / (\n","                    np.sum((labels_val == 1) & (predictions == 1)) + np.sum((labels_val == 1) & (predictions == 0)))\n","\n","            accuracy_list.append(accuracy)\n","            precision_list.append(precision)\n","            recall_list.append(recall)\n","\n","# Call the custom_k_fold_split function with your actual X_features and Y\n","custom_k_fold_split(X_features, Y)\n","\n","# Report final results\n","average_accuracy = np.mean(accuracy_list)\n","average_precision = np.mean(precision_list)\n","average_recall = np.mean(recall_list)\n","\n","print(f'Average Accuracy: {average_accuracy}')\n","print(f'Average Precision: {average_precision}')\n","print(f'Average Recall: {average_recall}')\n"]},{"cell_type":"markdown","metadata":{"id":"rdbecsZwPqiB"},"source":["# Question 2"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"nBntqImRkCbU"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set:\n"," [( 30000., 2., 1., 1., 0., 0., 0., 0., 0., 0., 3.3494e+04, 32978., 32415.,  30324.,  31124., 25502., 2506., 2430., 1300.,  1000., 3.4436e+04,  950., 1.)\n"," (160000., 1., 1., 2., 4., 3., 2., 2., 3., 2., 9.9340e+04, 96860., 99911., 103928., 101540., 99587.,    0., 5500., 6700.,     0., 2.7000e+01, 2800., 1.)\n"," (190000., 1., 1., 1., 2., 2., 2., 2., 2., 2., 3.6137e+04, 37143., 38051.,  38827.,  39488., 40208., 1900., 1800., 1700.,  1600., 1.5000e+03, 1600., 1.)\n"," (140000., 2., 1., 2., 0., 0., 0., 0., 0., 0., 3.1000e+01,  1272.,  1446.,   2880.,   1914.,   968., 2000., 1500., 3000.,  1914., 0.0000e+00, 3287., 1.)\n"," (200000., 2., 1., 3., 0., 0., 0., 0., 0., 0., 1.9920e+03,  8287.,  9427.,   2040.,  16338.,  2076., 8290., 9427., 2240., 16000., 2.0760e+03,  833., 0.)]\n","\n","Validation Set:\n"," [(100000., 1., 1., 1., 0., 0., 3., 2., 0., 0.,  4814.,  8311.,  8031.,  5790.,  3860.,  2599., 3591.,    0.,    0.,    0.,    0., 2712., 1.)\n"," (280000., 2., 1., 2., 0., 0., 0., 0., 0., 0., 91093., 92775., 81718., 83347., 85623., 87252., 3224., 2965., 2987., 3623., 3148., 3194., 0.)\n"," ( 60000., 1., 1., 1., 0., 0., 0., 0., 0., 0., 57985., 59312., 27420., 27965., 28552., 29276., 2550., 1500., 1001., 1038., 1200., 1233., 0.)\n"," ( 60000., 2., 1., 1., 0., 2., 2., 2., 2., 2.,  1577.,  2498.,  3309.,  3606.,  3400.,  3844., 1100., 1000.,  500.,    0.,  500.,    0., 0.)\n"," (200000., 2., 0., 2., 0., 0., 0., 0., 0., 0.,  1676.,  3122.,  2991.,   390.,  1211.,   390., 4595., 2991.,    0., 1211.,  390., 1112., 0.)]\n","\n","Testing Set:\n"," [(500000., 1., 1., 1., 1., 2., 2., 2., 2., 2.,  74850.,  76463.,  77611., 78735., 80430., 82068., 3400., 3000., 3000., 3100., 3110.,    0., 1.)\n"," ( 30000., 2., 0., 1., 0., 0., 0., 0., 0., 0.,  19282.,  20364.,  21638., 25392., 24428., 26410., 1700., 2617., 5710., 1000., 3342.,    0., 0.)\n"," ( 80000., 2., 1., 2., 1., 2., 0., 0., 2., 2.,   5999.,   5758.,   7039.,  7595.,  7053.,  7082.,    0., 1416.,  943.,  100.,  443.,    0., 1.)\n"," ( 20000., 2., 1., 2., 1., 2., 0., 0., 2., 0.,   6025.,   5786.,  10471., 11542., 11216., 14834.,    0., 5000., 1550.,    0., 4000., 4026., 1.)\n"," (140000., 1., 1., 2., 0., 0., 0., 0., 0., 0., 128947., 106671., 101362., 87420., 88774., 81869., 4039., 7010., 2359., 7617., 2760., 2366., 0.)]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","#loading all the data using the files provided\n","with open('pa2features.txt', 'r') as file:\n","    feature_names = [line.strip() for line in file.readlines()]\n","\n","feature_names.append('Label')\n","\n","# Define Structured Array DType\n","data_type = [(name, 'float64') for name in feature_names]\n","\n","# Load Datasets\n","training_set = np.loadtxt('pa2train.txt', dtype=data_type)\n","validation_set = np.loadtxt('pa2validation.txt', dtype=data_type)\n","testing_set = np.loadtxt('pa2test.txt', dtype=data_type)\n","\n","# Display First Few Rows\n","print(\"Training Set:\\n\", training_set[:5])\n","print(\"\\nValidation Set:\\n\", validation_set[:5])\n","print(\"\\nTesting Set:\\n\", testing_set[:5])\n"]},{"cell_type":"markdown","metadata":{"id":"IGKzXDA5ejix"},"source":["# Question 3 - Naive Bayes"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"elapsed":583,"status":"error","timestamp":1700983013534,"user":{"displayName":"Diya Roongta","userId":"11843916732539153564"},"user_tz":-330},"id":"jTXdicZbert-","outputId":"352c2370-0398-4745-c0b1-6500194c5626"},"outputs":[{"data":{"text/plain":["(26050, 1)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import pickle\n","\n","\n","file_path = 'hwdata.pkl'\n","\n","with open(file_path, 'rb') as file:\n","    data = pickle.load(file)\n","\n","\n","Vocabulary = data.get('Vocabulary')\n","XTrain = data.get('XTrain')\n","yTrain = data.get('yTrain')\n","XTest = data.get('XTest')\n","yTest = data.get('yTest')\n","\n","# Checking the shapes of the loaded arrays\n","Vocabulary.shape"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"IRQL8wErei-1"},"outputs":[],"source":["import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","\n","import pickle\n","\n","def NB_XGivenY(XTrain, yTrain, a=0.001, b=0.9):\n","    \"\"\"\n","    Compute the probability of P(X|Y).\n","\n","    :param\n","        XTrain: numpy array of size [num_samples, feat_dim]\n","          where num_samples is the number of samples\n","          and feat_dim is the dimension of features\n","        yTrain: numpy array of size [num_samples, 1]\n","        a: default to 0.001\n","        b: default to 0.9\n","\n","    :return:\n","        D: numpy array of size [2, vocab_size] where\n","          vocab_size is the size of vocabulary\n","    \"\"\"\n","    raise NotImplementedError\n","    return D\n","\n","\n","def NB_YPrior(yTrain):\n","    \"\"\"\n","    Compute the probability of P(Y).\n","\n","    :param\n","        yTrain: numpy array of size [num_samples, 1]\n","\n","    :return:\n","        p: a scalar for the probability of P(Y = 1)\n","    \"\"\"\n","    raise NotImplementedError\n","    return p\n","\n","\n","def NB_Classify(D, p, X):\n","    \"\"\"\n","    Predict the labels of X.\n","\n","    :param\n","        D: the probability P(X|Y)\n","        p: the probability P(Y)\n","        X: numpy array of size [num_samples, feat_dim]\n","          where num_samples is the number of samples\n","          and feat_dim is the dimension of features\n","\n","    :return:\n","        y: numpy array of size [num_samples, 1] where\n","            num_samples is the number of samples\n","    \"\"\"\n","    raise NotImplementedError\n","    return y\n","\n","\n","def NB_ClassificationAccuracy(yHat, yTruth):\n","    \"\"\"\n","    Compute the accuracy of predictions.\n","\n","    :param\n","        yHat: numpy array of size [num_samples, 1]\n","        yTruth: numpy array of size [num_samples, 1]\n","\n","    :return:\n","        acc: a scalar for the accuracy\n","    \"\"\"\n","    raise NotImplementedError\n","    return acc\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1BYZTcP1OO5LfpStUzkrJBcxop_cTxLmj","timestamp":1700983449474},{"file_id":"1jZs8rMsPI1VQgRaH7cXoq4n6odnI4cVG","timestamp":1700930899268}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
