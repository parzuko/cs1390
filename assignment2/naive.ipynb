{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Feature_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 97.39%\n",
      "Confusion Matrix:\n",
      " [[103   0]\n",
      " [  4  46]]\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "The Economist       0.96      1.00      0.98       103\n",
      "    The Onion       1.00      0.92      0.96        50\n",
      "\n",
      "     accuracy                           0.97       153\n",
      "    macro avg       0.98      0.96      0.97       153\n",
      " weighted avg       0.97      0.97      0.97       153\n",
      "\n",
      "Top 10 words that are most indicative of The Economist:\n",
      "1. ['4enlarg']\n",
      "2. ['5enlarg']\n",
      "3. ['percent']\n",
      "4. ['realiz']\n",
      "5. ['center']\n",
      "6. ['myself']\n",
      "7. ['approxim']\n",
      "8. ['honor']\n",
      "9. ['fuck']\n",
      "10. ['favor']\n",
      "Top 10 words that are most indicative of The Onion:\n",
      "1. ['parliament']\n",
      "2. ['organis']\n",
      "3. ['favour']\n",
      "4. ['labour']\n",
      "5. ['reckon']\n",
      "6. ['centr']\n",
      "7. ['neighbour']\n",
      "8. ['conserv']\n",
      "9. ['parliamentari']\n",
      "10. ['boost']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def NB_XGivenY(XTrain, yTrain, a=0.001, b=0.9):\n",
    "    \"\"\"\n",
    "    Compute the probability P(X|Y).\n",
    "    \"\"\"\n",
    "    num_samples, vocab_size = XTrain.shape\n",
    "    D = np.zeros((2, vocab_size))\n",
    "\n",
    "    for j in range(vocab_size):\n",
    "        D[0, j] = (np.sum(XTrain[yTrain[:, 0] == 1, j]) + a) / (np.sum(yTrain == 1) + a + b)\n",
    "        D[1, j] = (np.sum(XTrain[yTrain[:, 0] == 2, j]) + a) / (np.sum(yTrain == 2) + a + b)\n",
    "\n",
    "    return D\n",
    "\n",
    "def NB_YPrior(yTrain):\n",
    "    \"\"\"\n",
    "    Compute the probability P(Y).\n",
    "    \"\"\"\n",
    "    p = np.sum(yTrain == 1) / len(yTrain)\n",
    "    return p\n",
    "\n",
    "def NB_Classify(D, p, X):\n",
    "    \"\"\"\n",
    "    Predict the labels of X.\n",
    "    \"\"\"\n",
    "    num_samples, _ = X.shape\n",
    "    y = np.zeros((num_samples, 1))\n",
    "\n",
    "    log_D = np.log(D)\n",
    "    log_D_inv = np.log(1 - D)\n",
    "    log_prior = np.log(p)\n",
    "    log_prior_inv = np.log(1 - p)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        log_p_y1_given_x = np.sum(X[i, :] * log_D[0, :]) + np.sum((1 - X[i, :]) * log_D_inv[0, :]) + log_prior\n",
    "        log_p_y2_given_x = np.sum(X[i, :] * log_D[1, :]) + np.sum((1 - X[i, :]) * log_D_inv[1, :]) + log_prior_inv\n",
    "        y[i, 0] = 1 if log_p_y1_given_x > log_p_y2_given_x else 2\n",
    "\n",
    "    return y\n",
    "\n",
    "def NB_ClassificationAccuracy(yHat, yTruth):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of predictions.\n",
    "    \"\"\"\n",
    "    acc = np.sum(yHat == yTruth) / len(yTruth)\n",
    "    return acc\n",
    "\n",
    "# Load the data\n",
    "with open('hwdata.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "Vocabulary = data['Vocabulary']\n",
    "XTrain = data['XTrain']\n",
    "yTrain = data['yTrain']\n",
    "XTest = data['XTest']\n",
    "yTest = data['yTest']\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "D = NB_XGivenY(XTrain, yTrain)\n",
    "p = NB_YPrior(yTrain)\n",
    "\n",
    "# Classify the test data\n",
    "yHat = NB_Classify(D, p, XTest)\n",
    "\n",
    "# Calculate and report the accuracy\n",
    "accuracy = NB_ClassificationAccuracy(yHat, yTest)\n",
    "print(f\"Accuracy on Test Data: {accuracy * 100:.2f}%\")\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(yTest, yHat)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "#Classification Report (Precise, Reall, F-1 Score)\n",
    "report = classification_report(yTest, yHat, target_names=['The Economist', 'The Onion'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "#Feature Importance Analysis\n",
    "#Calculate the log probability ratio for each word\n",
    "log_prob_ratio = np.log(D[0, :]) - np.log(D[1, :])\n",
    "\n",
    "#Sort words by their log probability ratio\n",
    "sorted_idx = np.argsort(log_prob_ratio)\n",
    "\n",
    "#Print the top 10 words\n",
    "print(\"Top 10 words that are most indicative of The Economist:\")\n",
    "for i in range(10):\n",
    "    print(f\"{i + 1}. {Vocabulary[sorted_idx[i]]}\")\n",
    "\n",
    "print(\"Top 10 words that are most indicative of The Onion:\")\n",
    "for i in range(10):\n",
    "    print(f\"{i + 1}. {Vocabulary[sorted_idx[-i - 1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
